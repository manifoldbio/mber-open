from typing import Optional, List, Tuple, Dict, Union
from pathlib import Path
import os
import re
import requests
import json
import numpy as np
import boto3

from Bio import PDB
from Bio.PDB.Structure import Structure
from Bio.PDB.Model import Model
from Bio.PDB.Chain import Chain
from Bio.PDB.Residue import Residue

from mber.models.folding import ProteinFoldingModel


def process_target(target_id: str) -> tuple:
    """Process target protein from ID or file, returning PDB content and PAE matrix if available."""
    # Check if it's a file path and look for accompanying s3 file
    if os.path.exists(target_id):
        base_path = os.path.splitext(target_id)[0]
        pae_path = f"{base_path}_pae.json"
        if os.path.exists(pae_path):
            with open(pae_path, "r") as f:
                pae_matrix = parse_pae_matrix(f.read())
            with open(target_id, "r") as f:
                return f.read(), pae_matrix
        else:
            with open(target_id, "r") as f:
                return f.read(), None

    # check if its an s3 file and look for accompanying pae file on s3
    if target_id.startswith("s3://"):
        s3_client = boto3.client("s3")
        bucket_name = target_id.split("/")[2]
        file_key = "/".join(target_id.split("/")[3:])
        local_file_path = os.path.join("/tmp", os.path.basename(file_key))

        # Download the PDB file from S3
        s3_client.download_file(bucket_name, file_key, local_file_path)

        # Check for accompanying PAE file
        pae_key = file_key.replace(".pdb", "_pae.json")
        pae_local_path = os.path.join("/tmp", os.path.basename(pae_key))

        try:
            s3_client.download_file(bucket_name, pae_key, pae_local_path)
            with open(pae_local_path, "r") as f:
                pae_matrix = parse_pae_matrix(f.read())
        except Exception as e:
            print(f"PAE file not found: {e}")
            pae_matrix = None

        with open(local_file_path, "r") as f:
            return f.read(), pae_matrix

    # Check if it's a 4-letter PDB code
    if len(target_id) == 4 and target_id.isalnum():
        pdb_url = f"https://files.rcsb.org/download/{target_id}.pdb"
        response = requests.get(pdb_url)
        if response.status_code == 200:
            return response.text, None  # PDB files don't have PAE data
        else:
            raise ValueError(f"Failed to download PDB: {target_id}")

    # Check if it's a UniProt ID
    if len(target_id) >= 6 and target_id.isalnum():
        # Download AlphaFold structure
        af_url = f"https://alphafold.ebi.ac.uk/files/AF-{target_id}-F1-model_v6.pdb"
        response = requests.get(af_url)
        if response.status_code == 200:
            pdb_content = response.text

            # Also download the PAE file
            pae_url = f"https://alphafold.ebi.ac.uk/files/AF-{target_id}-F1-predicted_aligned_error_v6.json"
            pae_response = requests.get(pae_url)

            if pae_response.status_code == 200:
                pae_matrix = parse_pae_matrix(pae_response.text)
                return pdb_content, pae_matrix
            else:
                return pdb_content, None  # PAE file not available
        else:
            raise ValueError(f"Failed to download AlphaFold structure: {target_id}")

    raise ValueError(f"Invalid target ID format: {target_id}")


def parse_pae_matrix(pae_text: str):
    """
    Parse and validate the PAE matrix from a JSON file.
    Support both direct dictionary format and list-of-dictionaries format.
    """
    pae_data = json.loads(pae_text)

    # If it's a dictionary with the key directly
    if isinstance(pae_data, dict) and "predicted_aligned_error" in pae_data:
        full_pae_matrix = np.array(pae_data["predicted_aligned_error"])
    # If it's a list of dictionaries (original expected format)
    elif (
        isinstance(pae_data, list)
        and pae_data
        and "predicted_aligned_error" in pae_data[0]
    ):
        full_pae_matrix = np.array(pae_data[0]["predicted_aligned_error"])
    else:
        raise ValueError("PAE file must contain a 'predicted_aligned_error' field")

    return full_pae_matrix


def combine_structures(
    target_pdb: str,
    binder_pdb: str,
    target_chain: str,
    output_dir: Optional[Path] = None,
) -> str:
    """Combine target and binder structures."""
    # Create combined PDB manually
    combined_lines = ["HEADER    PROTEIN                                 01-JAN-25"]
    combined_lines.append(
        "TITLE     COMBINED TARGET AND BINDER STRUCTURE GENERATED BY MBER"
    )

    # Add target atoms (already have chain A)
    atom_count = 1
    target_atom_count = 0
    for line in target_pdb.splitlines():
        if line.startswith("ATOM"):
            # Update atom number
            new_line = f"ATOM  {atom_count:5d}{line[11:]}"
            combined_lines.append(new_line)
            atom_count += 1
            target_atom_count += 1

    # Add TER record after target
    combined_lines.append(f"TER   {atom_count:5d}      {target_chain}")

    # Add binder atoms with chain H
    binder_atom_count = 0
    for line in binder_pdb.splitlines():
        if line.startswith("ATOM"):
            # Update atom number and chain
            new_line = f"ATOM  {atom_count:5d}{line[11:21]}H{line[22:]}"
            combined_lines.append(new_line)
            atom_count += 1
            binder_atom_count += 1

    # Add TER and END markers
    if binder_atom_count > 0:
        combined_lines.append(f"TER   {atom_count:5d}      H")

    # Add end marker
    combined_lines.append("END")

    # Join to create PDB content
    combined_pdb = "\n".join(combined_lines)

    # Write combined structure to file if output_dir provided
    if output_dir:
        combined_path = output_dir / "combined.pdb"
        with open(combined_path, "w") as f:
            f.write(combined_pdb)

        # Also write individual structures for debugging
        with open(output_dir / "target_debug.pdb", "w") as f:
            f.write(target_pdb)
        with open(output_dir / "binder_debug.pdb", "w") as f:
            f.write(binder_pdb)

    return combined_pdb


def manual_renumber_pdb(input_path: str, output_path: str, sequence: str) -> None:
    """Manually renumber PDB file residues sequentially starting from 1."""
    # Read the input PDB
    with open(input_path, "r") as f:
        lines = f.readlines()

    # Initialize variables
    new_lines = []
    current_res_num = None
    new_res_num = 0  # Start at 0 so first increment makes it 1
    atom_num = 1

    # Process each line
    for line in lines:
        if line.startswith("ATOM"):
            # Extract fields
            res_num = int(line[22:26])

            # If we've moved to a new residue, increment new_res_num
            if res_num != current_res_num:
                current_res_num = res_num
                new_res_num += 1  # Always increment for a new residue

            # Create new line with updated residue and atom numbers
            new_line = f"ATOM  {atom_num:5d}{line[11:22]}{new_res_num:4d}{line[26:]}"
            new_lines.append(new_line)
            atom_num += 1
        elif line.startswith("TER") or line.startswith("END"):
            # Include TER and END markers
            new_lines.append(line)

    # Write output PDB
    with open(output_path, "w") as f:
        f.writelines(new_lines)


def fold_binder(
    folding_model: ProteinFoldingModel, sequence: str, output_dir: Optional[Path] = None
) -> str:
    """Fold binder sequence using a structure prediction model."""
    # Create output paths
    raw_output_path = (
        str(output_dir / "binder_raw.pdb") if output_dir else "binder_raw.pdb"
    )
    renumbered_output_path = (
        str(output_dir / "binder.pdb") if output_dir else "binder.pdb"
    )

    # Fold sequence
    folding_model.predict_structure(sequence, raw_output_path)

    # Renumber the PDB file
    manual_renumber_pdb(raw_output_path, renumbered_output_path, sequence)

    # Read PDB content
    with open(renumbered_output_path, "r") as f:
        pdb_content = f.read()

    return pdb_content
